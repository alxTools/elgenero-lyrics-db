base_model: mistral:7b
adapter: lora
datasets:
  - path: dataset_lyrics_fixed.jsonl
train:
  output_dir: reggaeton_lyrics_finetuned
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 2e-4
  num_train_epochs: 3
