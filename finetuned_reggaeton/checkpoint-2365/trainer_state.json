{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.990496304118269,
  "eval_steps": 500,
  "global_step": 2365,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10559662090813093,
      "grad_norm": 8.095292091369629,
      "learning_rate": 1.961945031712474e-05,
      "loss": 8.4854,
      "step": 50
    },
    {
      "epoch": 0.21119324181626187,
      "grad_norm": 6.221933841705322,
      "learning_rate": 1.919661733615222e-05,
      "loss": 6.808,
      "step": 100
    },
    {
      "epoch": 0.3167898627243928,
      "grad_norm": 7.295735836029053,
      "learning_rate": 1.8773784355179705e-05,
      "loss": 6.5006,
      "step": 150
    },
    {
      "epoch": 0.42238648363252373,
      "grad_norm": 7.862524032592773,
      "learning_rate": 1.835095137420719e-05,
      "loss": 6.4136,
      "step": 200
    },
    {
      "epoch": 0.5279831045406547,
      "grad_norm": 10.445564270019531,
      "learning_rate": 1.7928118393234674e-05,
      "loss": 6.3477,
      "step": 250
    },
    {
      "epoch": 0.6335797254487856,
      "grad_norm": 9.348127365112305,
      "learning_rate": 1.750528541226216e-05,
      "loss": 6.3144,
      "step": 300
    },
    {
      "epoch": 0.7391763463569165,
      "grad_norm": 7.95535945892334,
      "learning_rate": 1.708245243128964e-05,
      "loss": 6.2819,
      "step": 350
    },
    {
      "epoch": 0.8447729672650475,
      "grad_norm": 9.225866317749023,
      "learning_rate": 1.6659619450317125e-05,
      "loss": 6.261,
      "step": 400
    },
    {
      "epoch": 0.9503695881731784,
      "grad_norm": 9.499421119689941,
      "learning_rate": 1.623678646934461e-05,
      "loss": 6.2202,
      "step": 450
    },
    {
      "epoch": 1.0549102428722281,
      "grad_norm": 10.564906120300293,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 6.2084,
      "step": 500
    },
    {
      "epoch": 1.160506863780359,
      "grad_norm": 9.055171966552734,
      "learning_rate": 1.539112050739958e-05,
      "loss": 6.1788,
      "step": 550
    },
    {
      "epoch": 1.26610348468849,
      "grad_norm": 7.637308120727539,
      "learning_rate": 1.4968287526427063e-05,
      "loss": 6.1924,
      "step": 600
    },
    {
      "epoch": 1.371700105596621,
      "grad_norm": 7.503878593444824,
      "learning_rate": 1.4545454545454546e-05,
      "loss": 6.1699,
      "step": 650
    },
    {
      "epoch": 1.4772967265047519,
      "grad_norm": 8.64782428741455,
      "learning_rate": 1.4122621564482031e-05,
      "loss": 6.1824,
      "step": 700
    },
    {
      "epoch": 1.5828933474128828,
      "grad_norm": 8.475740432739258,
      "learning_rate": 1.3699788583509514e-05,
      "loss": 6.1535,
      "step": 750
    },
    {
      "epoch": 1.6884899683210137,
      "grad_norm": 8.237421035766602,
      "learning_rate": 1.3276955602536997e-05,
      "loss": 6.1426,
      "step": 800
    },
    {
      "epoch": 1.7940865892291447,
      "grad_norm": 7.767821788787842,
      "learning_rate": 1.2854122621564482e-05,
      "loss": 6.1282,
      "step": 850
    },
    {
      "epoch": 1.8996832101372756,
      "grad_norm": 11.526690483093262,
      "learning_rate": 1.2431289640591969e-05,
      "loss": 6.1502,
      "step": 900
    },
    {
      "epoch": 2.0042238648363253,
      "grad_norm": 9.32812213897705,
      "learning_rate": 1.2008456659619452e-05,
      "loss": 6.114,
      "step": 950
    },
    {
      "epoch": 2.1098204857444562,
      "grad_norm": 9.986845970153809,
      "learning_rate": 1.1585623678646935e-05,
      "loss": 6.1231,
      "step": 1000
    },
    {
      "epoch": 2.215417106652587,
      "grad_norm": 12.595620155334473,
      "learning_rate": 1.116279069767442e-05,
      "loss": 6.1029,
      "step": 1050
    },
    {
      "epoch": 2.321013727560718,
      "grad_norm": 18.054580688476562,
      "learning_rate": 1.0739957716701903e-05,
      "loss": 6.0925,
      "step": 1100
    },
    {
      "epoch": 2.426610348468849,
      "grad_norm": 7.895008563995361,
      "learning_rate": 1.0317124735729386e-05,
      "loss": 6.1211,
      "step": 1150
    },
    {
      "epoch": 2.53220696937698,
      "grad_norm": 8.728800773620605,
      "learning_rate": 9.894291754756871e-06,
      "loss": 6.1034,
      "step": 1200
    },
    {
      "epoch": 2.637803590285111,
      "grad_norm": 7.494461536407471,
      "learning_rate": 9.471458773784356e-06,
      "loss": 6.0923,
      "step": 1250
    },
    {
      "epoch": 2.743400211193242,
      "grad_norm": 10.523252487182617,
      "learning_rate": 9.048625792811841e-06,
      "loss": 6.0771,
      "step": 1300
    },
    {
      "epoch": 2.848996832101373,
      "grad_norm": 9.677794456481934,
      "learning_rate": 8.625792811839324e-06,
      "loss": 6.1004,
      "step": 1350
    },
    {
      "epoch": 2.9545934530095037,
      "grad_norm": 12.573227882385254,
      "learning_rate": 8.202959830866807e-06,
      "loss": 6.0963,
      "step": 1400
    },
    {
      "epoch": 3.0591341077085534,
      "grad_norm": 8.801794052124023,
      "learning_rate": 7.780126849894292e-06,
      "loss": 6.073,
      "step": 1450
    },
    {
      "epoch": 3.1647307286166844,
      "grad_norm": 9.32737922668457,
      "learning_rate": 7.357293868921777e-06,
      "loss": 6.0671,
      "step": 1500
    },
    {
      "epoch": 3.2703273495248153,
      "grad_norm": 14.704506874084473,
      "learning_rate": 6.93446088794926e-06,
      "loss": 6.0697,
      "step": 1550
    },
    {
      "epoch": 3.3759239704329462,
      "grad_norm": 13.322519302368164,
      "learning_rate": 6.511627906976745e-06,
      "loss": 6.086,
      "step": 1600
    },
    {
      "epoch": 3.481520591341077,
      "grad_norm": 11.031265258789062,
      "learning_rate": 6.088794926004229e-06,
      "loss": 6.0479,
      "step": 1650
    },
    {
      "epoch": 3.587117212249208,
      "grad_norm": 9.649771690368652,
      "learning_rate": 5.665961945031713e-06,
      "loss": 6.0865,
      "step": 1700
    },
    {
      "epoch": 3.692713833157339,
      "grad_norm": 21.405498504638672,
      "learning_rate": 5.243128964059198e-06,
      "loss": 6.0851,
      "step": 1750
    },
    {
      "epoch": 3.79831045406547,
      "grad_norm": 14.856895446777344,
      "learning_rate": 4.820295983086682e-06,
      "loss": 6.0736,
      "step": 1800
    },
    {
      "epoch": 3.903907074973601,
      "grad_norm": 10.686358451843262,
      "learning_rate": 4.397463002114165e-06,
      "loss": 6.0643,
      "step": 1850
    },
    {
      "epoch": 4.008447729672651,
      "grad_norm": 9.99212646484375,
      "learning_rate": 3.97463002114165e-06,
      "loss": 6.0878,
      "step": 1900
    },
    {
      "epoch": 4.114044350580781,
      "grad_norm": 9.815731048583984,
      "learning_rate": 3.5517970401691337e-06,
      "loss": 6.0764,
      "step": 1950
    },
    {
      "epoch": 4.2196409714889125,
      "grad_norm": 9.634401321411133,
      "learning_rate": 3.1289640591966173e-06,
      "loss": 6.0517,
      "step": 2000
    },
    {
      "epoch": 4.325237592397043,
      "grad_norm": 10.835952758789062,
      "learning_rate": 2.7061310782241017e-06,
      "loss": 6.0862,
      "step": 2050
    },
    {
      "epoch": 4.430834213305174,
      "grad_norm": 9.945573806762695,
      "learning_rate": 2.2832980972515857e-06,
      "loss": 6.0625,
      "step": 2100
    },
    {
      "epoch": 4.536430834213305,
      "grad_norm": 10.840032577514648,
      "learning_rate": 1.86046511627907e-06,
      "loss": 6.0415,
      "step": 2150
    },
    {
      "epoch": 4.642027455121436,
      "grad_norm": 10.058977127075195,
      "learning_rate": 1.437632135306554e-06,
      "loss": 6.0752,
      "step": 2200
    },
    {
      "epoch": 4.747624076029567,
      "grad_norm": 14.10940170288086,
      "learning_rate": 1.0147991543340381e-06,
      "loss": 6.0463,
      "step": 2250
    },
    {
      "epoch": 4.853220696937698,
      "grad_norm": 9.163729667663574,
      "learning_rate": 5.919661733615223e-07,
      "loss": 6.0649,
      "step": 2300
    },
    {
      "epoch": 4.958817317845829,
      "grad_norm": 9.848546028137207,
      "learning_rate": 1.6913319238900636e-07,
      "loss": 6.0577,
      "step": 2350
    }
  ],
  "logging_steps": 50,
  "max_steps": 2365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.064586754878341e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
